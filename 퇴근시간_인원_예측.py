# -*- coding: utf-8 -*-
"""퇴근시간 인원 예측

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dMXrF_osqhEF7E5N4ZhKXOOymJVY-xlK
"""

# !pip install pycaret[full]
# !pip install seaborn
# !pip install holidays
# !pip install geopy

# import
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import geopy.distance as distance
from pycaret.regression import *
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler, Normalizer, OneHotEncoder
import holidays as holidays

# coord_df = pd.read_csv('coordinate.csv', encoding='utf-8')
# coord_df['latitude'] = coord_df['latitude'].round(2)
# coord_df['longitude'] = coord_df['longitude'].round(1)

# 라벨 인코더
le = LabelEncoder()
# 원-핫 인코더
ohe = OneHotEncoder(sparse_output=False)
# 스케일러
scaler = StandardScaler()
# 정규화
normalizer = Normalizer()

def trans_data(df):
    # 날짜
    df['date'] = pd.to_datetime(df['date'])
    ## 날짜2
    df['day'] = df['date'].dt.day
    df['weekday'] = df['date'].dt.weekday

    # 주말
    df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x in [5, 6] else 0)

    # 공휴일 여부
    kr_holidays = holidays.KR(years=2019)
    df['is_holiday'] = df['date'].isin(kr_holidays.keys())

    # 시간별 승하차 인원
    df['6~8_ride'] = df[['6~7_ride','7~8_ride']].sum(1)
    df['8~10_ride'] = df[['8~9_ride','9~10_ride']].sum(1)
    df['10~12_ride'] = df[['10~11_ride','11~12_takeoff']].sum(1)
    df['6~8_takeoff'] = df[['6~7_takeoff','7~8_takeoff']].sum(1)
    df['8~10_takeoff'] = df[['8~9_takeoff','9~10_takeoff']].sum(1)
    df['10~12_takeoff'] = df[['10~11_takeoff','11~12_takeoff']].sum(1)

    # 거리 계산
    north_coord = (33.524807, 126.513258)     # 제주시
    south_coord = (33.266964, 126.563705)   # 서귀포시
    east_coord = (33.515892, 126.883168)
    west_coord = (33.3341191, 126.1815651)
    df['north_distance'] = df.apply(lambda row: distance.distance(north_coord, (row['latitude'], row['longitude'])).km, axis=1)
    df['south_distance'] = df.apply(lambda row: distance.distance(south_coord, (row['latitude'], row['longitude'])).km, axis=1)
    df['east_distance'] = df.apply(lambda row: distance.distance(east_coord, (row['latitude'], row['longitude'])).km, axis=1)
    df['west_distance'] = df.apply(lambda row: distance.distance(west_coord, (row['latitude'], row['longitude'])).km, axis=1)


    # 지역
    df['lat_lon1'] = df['latitude'].round(2).astype(str)+df['longitude'].round(2).astype(str)
    df['lat_lon2'] = df['latitude'].round(3).astype(str)+df['longitude'].round(3).astype(str)
    df['lat_lon1'] = le.fit_transform(df['lat_lon1'])
    df['lat_lon2'] = le.fit_transform(df['lat_lon2'])

    # 시외, 시내
    df['in_out'] = df['in_out'].apply(lambda x: 1 if x == '시외' else 0)

    # 원 핫 인코딩
    one_features = ['weekday']
    encoded = ohe.fit_transform(df[one_features])
    encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(one_features))
    df = pd.concat([df.drop(columns=one_features), encoded_df], axis=1)

    # 필요 없는 값 삭제
    df.drop(columns=['id', 'station_name', 'date'], inplace=True, axis=1)
    df.drop(columns=['6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',
                     '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',
                     'latitude', 'longitude'],
            inplace=True, axis=1)

    return df

pd.set_option('display.max_columns', None)
# 1. 데이터
train_df =  pd.read_csv('train.csv', encoding='utf-8')
test_df =  pd.read_csv('test.csv', encoding='utf-8')

train_df = trans_data(train_df)
test_df = trans_data(test_df)

train_df.head()
# test_df.head()

# 시각화
## 히트맵
sns.set(rc={'figure.figsize':(20, 12)})
sns.heatmap(data=train_df.corr(), square=True, annot=True, cbar=True)
plt.show()

# 2. setup
s = setup(
    session_id=123,
    data = train_df,
    target = '18~20_ride',
    train_size=0.8,
    categorical_features=['bus_route_id', 'station_code', 'in_out', 'is_holiday', 'is_weekend'],
    verbose=True,
    # use_gpu=True
)

# get_config('X_train')
get_config('X_train_transformed')

# 가장 좋은 모델 찾기
model = compare_models(sort='MAE')
# top3 = compare_models(sort='MAE', n_select=3)

# 특정 모델 선택
# model = create_model('rf')

# ensemble
# tuned_top3 = [tune_model(i, optimize='MAE', search_library = 'optuna') for i in top3]
# best = blend_models(top3, optimize='MAE')
# stack_lr = stack_models(best, optimize='MAE', choose_better=True)
# model = finalize_model(stack_lr)

# # 그래프
# evaluate_model(model)
# plot_model(model, plot = 'residuals')
# plot_model(model, plot = 'feature')
# interpret_model(model, plot='summary', observation=100)  # 100개 샘플만 SHAP 계산

# 예측점수
predict_model(model)

# 예측하기
predictions = predict_model(model, data=test_df)
predictions

# 예측값을 반올림하여 정수로 변환
predictions['prediction_label'] = predictions['prediction_label'].round()
predictions['prediction_label'] = predictions['prediction_label'].astype(int)

# 컬럼 이름 변경
predictions = predictions.rename(columns={'prediction_label': '18~20_ride'})

# submission_sample.csv 읽기
submission_sample = pd.read_csv('submission_sample.csv')

# 예측값 '18~20_takeoff' 컬럼을 submission_sample에 합치기
submission_sample['18~20_ride'] = predictions['18~20_ride']

# 결과를 새로운 CSV로 저장
submission_sample.to_csv('submission.csv', index=False)

# 결과 확인
print(submission_sample.head())